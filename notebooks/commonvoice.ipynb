{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook for exploring CommonVoice dataset\n",
    "\n",
    "import torchaudio\n",
    "import soundfile as sf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from IPython.display import Audio, display\n",
    "from torchaudio.transforms import MelSpectrogram\n",
    "\n",
    "from zoraspeech.utils import visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up autoreload\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMON_VOICE_PATH = \"/Volumes/entryplug_unit02/common_voice/commonvoice/cv-corpus-17.0-2024-03-15/en/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in tsv into pandas dataframe\n",
    "df = pd.read_csv(COMMON_VOICE_PATH + \"train.tsv\", sep=\"\\t\")\n",
    "\n",
    "# print the first 5 rows of the dataframe for jupyter notebook\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of rows in the dataframe\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the first 5 rows, print the sentence and the audio path, an audio player, a waveform, and a specgram\n",
    "\n",
    "for i in range(5):\n",
    "    sentence = df.iloc[i]['sentence']\n",
    "    path = COMMON_VOICE_PATH + 'clips_wav/' + df.iloc[i]['path'].replace(\"mp3\", \"wav\")\n",
    "    print(sentence)\n",
    "    print(path)\n",
    "    display(Audio(path))\n",
    "\n",
    "    # load in the audio file\n",
    "    audio, sr = torchaudio.load(path)\n",
    "\n",
    "    # visualize the waveform and specgram\n",
    "\n",
    "    visualization.plot_waveform(audio, sr)\n",
    "    visualization.plot_specgram(audio, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
